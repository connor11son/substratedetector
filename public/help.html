<h1>Underwater Substrate Classification</h1>
<p>Marine Applied Research and Exploration (MARE) has collected hundreds of hours of video using their unmanned, underwater, remote-operated vehicles (ROVs). In order to better survey and understand life in California's costal waters, MARE has annotated each video with species and substrate labels. </p>
<p>As a first step toward creating a ontext-Driven Detector for underwater species, we first implemented a method using a convolutional neural network (CNN) capable of generating temporal labels for DUSIA. A ResNet-based classification models classifies the video frame by frame.</p>
<h2>Input</h2>
<p>.mp4 video</p>
<h2>Output</h2>
<p>.csv with predicted substrate for each frame in the video</p>
<h1>Want to know more?</h1>
<p><a href="https://www.austinmcever.com/CDD4DUSIA" target="_blank">Check out the project here</a>.</p>